{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e44f8ff1-ee4d-452e-8f9f-d36fdf9e9d3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================\n",
      "Processing... data/kr.pdf\n",
      "================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Koushik M A\n",
      "\n",
      "9742836226  \n",
      "\n",
      "koushikma62@gmail.com\n",
      "\n",
      "linkedin.com/in/koushik-ma-6378001b7  \n",
      "\n",
      "## PROFILE\n",
      "\n",
      "Experienced Data Analytics Consultant with 4+ years in data visualization, product development, and some  exposure to data engineering and data science. Skilled at turning data into clear insights and building easy- to-use visual tools to support business goals. Strong problem-solver with a focus on delivering effective,  data-driven solutions.\n",
      "\n",
      "## PROFESSIONAL EXPERIENCE\n",
      "\n",
      "Mathco (TheMathCompany), \n",
      "\n",
      "Product Engineer - II (Data Visualisation Using Python)\n",
      "\n",
      "- • Guided multiple teams through the product development process, focusing on data visualization and  simplifying complex data science methodologies for better understanding.\n",
      "- • Collaborated closely with customers to ensure that the products aligned with their business needs and  were easy to interpret.\n",
      "- • Successfully converted 2 proof-of-concept (POC) projects into full-time engagements for clients within a  short timeframe, driving significant business growth to our organization.\n",
      "\n",
      "Associate\n",
      "\n",
      "• Worked with Fortune 500 clients to demonstrate data science methodology results in our product.\n",
      "\n",
      "- • Migrated data reading from blob storage to Snowflake and optimized the code, significantly improving  load times and enhancing customer experience.\n",
      "- • Created training materials and trained 100+ employees, including managers, on effectively using the  product and developing data visualization screens.\n",
      "\n",
      "Data Analyst\n",
      "\n",
      "• Tested data science functionalities during the early stages of product development.\n",
      "\n",
      "- • Created 100+ demo applications to showcase product capabilities, helping secure client agreements and  convert some into full-time projects for data visualization.\n",
      "\n",
      "## SKILLS\n",
      "\n",
      "## Technologies:\n",
      "\n",
      "Python, SQL, FastAPI, Basic visualisations in  Power BI\n",
      "\n",
      "Libraries/Framework:\n",
      "\n",
      "NumPy, Pandas, Plotly\n",
      "\n",
      "Tools Used:\n",
      "\n",
      "VS Code, Jupyter notebook  \n",
      "\n",
      "PostgreSQL, Snowflake\n",
      "\n",
      "## EDUCATION\n",
      "\n",
      "University Visvesvaraya College of Engineering,  BE in Computer Science &amp; Engineering; 72.07 Aggregate\n",
      "\n",
      "AWARDS\n",
      "\n",
      "Enterprise Value Award\n",
      "\n",
      "Recognized for driving speed and prioritizing innovation by managing full product development without  the need for new UI development.\n",
      "\n",
      "Aug 2016 - Sep 2020\n",
      "\n",
      "Jul 2024 - present\n",
      "\n",
      "Jul 2022 - Jun 2024\n",
      "\n",
      "Total document prediction time: 519.39 seconds, pages: 1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import yaml\n",
    "\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import (\n",
    "    AcceleratorDevice,\n",
    "    VlmPipelineOptions,\n",
    "    granite_vision_vlm_conversion_options,\n",
    "    smoldocling_vlm_conversion_options,\n",
    "    smoldocling_vlm_mlx_conversion_options,\n",
    ")\n",
    "from docling.datamodel.settings import settings\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.pipeline.vlm_pipeline import VlmPipeline\n",
    "\n",
    "sources = [\n",
    "    # \"tests/data/2305.03393v1-pg9-img.png\",\n",
    "    \"data/kr.pdf\",\n",
    "]\n",
    "\n",
    "## Use experimental VlmPipeline\n",
    "pipeline_options = VlmPipelineOptions()\n",
    "# If force_backend_text = True, text from backend will be used instead of generated text\n",
    "pipeline_options.force_backend_text = True\n",
    "\n",
    "## Pick a VLM model. Fast Apple Silicon friendly implementation for SmolDocling-256M via MLX\n",
    "pipeline_options.vlm_options = smoldocling_vlm_conversion_options\n",
    "\n",
    "#pipeline_options.vlm_options = granite_vision_vlm_conversion_options\n",
    "from docling_core.types.doc import DocItemLabel, ImageRefMode\n",
    "from docling_core.types.doc.document import DEFAULT_EXPORT_LABELS\n",
    "\n",
    "## Set up pipeline for PDF or image inputs\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(\n",
    "            pipeline_cls=VlmPipeline,\n",
    "            pipeline_options=pipeline_options,\n",
    "        ),\n",
    "        InputFormat.IMAGE: PdfFormatOption(\n",
    "            pipeline_cls=VlmPipeline,\n",
    "            pipeline_options=pipeline_options,\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "out_path = Path(\"scratch\")\n",
    "out_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for source in sources:\n",
    "    start_time = time.time()\n",
    "    print(\"================================================\")\n",
    "    print(\"Processing... {}\".format(source))\n",
    "    print(\"================================================\")\n",
    "    print(\"\")\n",
    "\n",
    "    res = converter.convert(source)\n",
    "    print(\"\")\n",
    "    print(res.document.export_to_markdown())\n",
    "    res.document.save_as_html(\n",
    "        filename=Path(\"{}/{}.html\".format(out_path, res.input.file.stem)),\n",
    "        image_mode=ImageRefMode.REFERENCED,\n",
    "        labels=[*DEFAULT_EXPORT_LABELS, DocItemLabel.FOOTNOTE],\n",
    "    )\n",
    "    res.document.save_as_markdown(\n",
    "        out_path / f\"{res.input.file.stem}.md\",\n",
    "        image_mode=ImageRefMode.PLACEHOLDER,\n",
    "    )\n",
    "\n",
    "    pg_num = res.document.num_pages()\n",
    "    print(\"\")\n",
    "    inference_time = time.time() - start_time\n",
    "    print(\n",
    "        f\"Total document prediction time: {inference_time:.2f} seconds, pages: {pg_num}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48c51296-128d-4e04-9e05-defc7d02650a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "327b0ad2-6e3b-455c-98c8-8be6be9a19ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm_gemini = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "603558c7-fe6a-4920-9b29-f75103ff11bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00b5a00e-607d-4105-a43d-ab90c0078057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Mohan Reddy Pallavula\n",
      "linkedin/mohanreddypallavula github/mohanreddypallavula\n",
      "Experience\n",
      "## · Matdun Labs India Pvt. Ltd\n",
      "Remote\n",
      "Dec 2021 - present\n",
      "- AI Engineer (Full-time)\n",
      "- ◦ Face Recognition system : Developed an advanced face recognition system utilizing SOTA based models for detecting and recognition the face and deployed on edge device (jetson nano) and kubernetes cluster (Nvidia Gpus). Optimized the models using tensorrt to reduce latency and Used Nvidia Triton server for dynamic batching, GPU and CPU optimization, and robust scalability, ensuring efficient and high-performance inference for deployed AI models. Tech: Tensorrt , Nvidia Jetson Nano , Kubernetes , Docker , FastAPI , Django , Web sockets , Grpc ,Pytorch , Opencv , Scikit-learn , PostgresSQL , Azure blob , GIT\n",
      "- ◦ Video Analytics System : Delevoped an advanced AI-powered solution designed for real-time monitoring and analysis of video streams. It offers features such as person tracking, which enables precise identification and movement analysis, and person analytics, including metrics like waiting time and behavior patterns. The system incorporates specialized detection capabilities, such as weapon detection for enhanced security and fall detection for safety monitoring in environments.\n",
      "- Tech: Tensorrt , Kubernetes , Docker , FastAPI , Redis , Grpc , Pytorch Lightning , Litdata , Opencv , Scikit-learn , Nvidia Trition Server , Nvidia deepstream , Pytorch , MLflow , GIT , PostgresSQL , Azure blob\n",
      "- ◦ Generate Description based on activities : Automatically generate detailed and contextually accurate descriptions of activities. We used few shot prompting and llama 3 model to develop the system. Tech: LitGPT , pytorch lightning , Litserve , FastAPI , Redis , QLora , Azure blob , Langchain , Langgraph , Azure Cloud , OpenAI API(GPT-4o) , Llama 3 , RAG\n",
      "## · Capillary Technologies Pvt Ltd\n",
      "Remote\n",
      "June 2021 - Nov 2021\n",
      "- ML Intern (Full-time)\n",
      "- ◦ Smart Store : Developed an advanced deep learning to detect the person age group , identifies fashion types, such as specific dress styles.\n",
      "- Developed person tracking to analyze customer behavior within the store. By tracking where individuals spend their time, the system provides insights into high-traffic areas and zones of interest.\n",
      "- Tech: Deep Learning , AWS , Computer Vision , Nodejs , Docker , GIT\n",
      "## · Appcilious Pvt. Ltd\n",
      "Remote\n",
      "Sep 2020 - Nov 2020\n",
      "- ML Intern (Full-time)\n",
      "- ◦ Fake News Classification : Developed an advanced text analysis techniques to accurately identify and categorize misinformation. It employs TF-IDF for initial text feature extraction, Word2Vec for capturing semantic word relationships, and transformer-based embeddings, specifically the Universal Sentence Encoder, for deep contextual understanding. By combining these methods, the system enhances its ability to discern fake news from credible sources. Tech: Machine Learning , NLTK , Scikit-learn , Tf-idf , Deep learning , word2vec.\n",
      "## Skills Summary\n",
      "- · Core Expertise : Data Science, Machine Learning, Deep Learning, Natural Language Processing (NLP), Computer Vision, Predictive Modeling, Decision Analytics, Large Language Models (LLMs), Generative AI\n",
      "- · Languages :\n",
      "Python, C , C++\n",
      "- · Frameworks : Pytorch , Scikit-learn , FastAPI , Django, Flask , Nvidia Deepestream , Nvidia Triton Server , Langgraph , Langchain , Litgpt , Litdata , Pytorch lightning , Huggingface libraries ( Transformers , peft)\n",
      "- · Tools :\n",
      "Kubernetes, Docker, GIT, PostgreSQL, Redis , Gitlab CI-CD\n",
      "- · Platforms : Linux, Web, Windows, Nvidia Jetson Nano, Raspberry , Azure , Basic Aws\n",
      "- · Soft Skills :\n",
      "Leadership, Time Management\n",
      "Projects\n",
      "- · Implemented Tinyllama from scratch in pytorch : Built a lightweight version of the LLaMA language model from the ground up using PyTorch, focusing on replicating core transformer architecture with an emphasis on model efficiency and size reduction. Loaded the pretrained weights into our architecture and implemented inference pipeline. Implemented client and server using grpc python.\n",
      "- Tech: PyTorch, Transformers, Attention Mechanisms, Deep Learning , KV cache , Grpc , LLM, GenAI .\n",
      "- · Image Captioning using Deep Learning (NLP, CV) : Developed an advanced image captioning system using an encoder-decoder architecture to automatically generate coherent and contextually relevant textual descriptions from images. Tech: Python, Tensorflow, Streamlit , and Deep Learning\n",
      "- · Semantic search engine on stackoverflow python data (NLP) : Developed a robust semantic search engine designed to enhance search accuracy and relevance within StackOverflow Python data by leveraging advanced natural language processing techniques.\n",
      "- Tech: Python, Natural Language Processing (NLP), Word Embeddings, TF-IDF, Transformer Models, Elasticsearch, Scikit-learn, and Pandas.\n",
      "- · Face Recognition using Deep Learning : Developed an advanced face recognition system utilizing deep learning techniques to accurately identify and verify individuals from images, with applications in security, identity verification. Tech: Python, Pytorch, Convolutional Neural Networks (CNN), OpenCV, Scikit-learn, TensorRT , Nvidia Jetson nano , fastapi , and Web sockets.\n",
      "Mobile:\n",
      "+91-8309913459\n",
      "Email: mohanreddy.pmg@gmail.com\n",
      "• Bachelor of Technology - Computer Science and Engineering; GPA: 8.0\n",
      "## JNTUA Engineering College\n",
      "Kalikiri , AP , India\n",
      "July 2017 - June 2021\n",
      "• Intermediate - MPC; Per: 96.7\n",
      "Sri Chaitanya Junior College\n",
      "Tirupati , AP , India\n",
      "July 2015 - June 2017\n",
      "• AP Residential School\n",
      "Gyaram Palli , AP , India\n",
      "SSC ; GPA: 9.5\n",
      "July 2008 - Apr 2015\n",
      "## Competitions\n",
      "- · CODING AT GMOCS-2K18 2K19 : secured 1st position in a one-day national level technical symposium organized by MITS,department of CSE ( Mar 2019 ).\n",
      "- · CODING AT ECLECTICA-2019 : secured 2nd position in a one-day national level technical symposium organized by MITS ,department of ECE (April 2019).\n",
      "- · PRATIBHA AWARD-2015 : Selected for prathibha award scholarship for securing highest grade in SSC Examination 2015.\n",
      "- · 42nd MATHEMATICAL OLYMPIAD-2016 : Secured 6th position in the 42nd mathematical olympiad held in 2014 throughout the state of Andhra pradesh at the Mini-Junior/Sub Junior/Junior/Senior/Junior Inter/Senior Inter/Level.\n",
      "## Honors and Awards\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_ = ''\n",
    "for i in clean_text.split('\\n'):\n",
    "    j = i\n",
    "    if j.strip() != '':\n",
    "        text_ += i +'\\n'\n",
    "print(text_)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "213c5b19-96c4-4bb5-b6ca-c01ca1bee0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resume_chunking_prompt(resume_text: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "You are an intelligent document parser designed to preprocess resumes for a Retrieval-Augmented Generation (RAG) system.\n",
    "Your task is to intelligently chunk the given raw resume content into well-defined sections for semantic retrieval. Focus on structuring the data meaningfully and consistently so that downstream models can retrieve relevant information efficiently.\n",
    "Specifically, divide the resume into the following labeled sections:\n",
    "1. Personal Details\n",
    "   - Full name, email, phone number, LinkedIn, GitHub, portfolio links, address (if present).\n",
    "2. Education\n",
    "   - Degrees, institutions, years of study, relevant coursework or achievements.\n",
    "3. Work Experience\n",
    "   - Job titles, company names, duration, responsibilities, technologies used, accomplishments.\n",
    "4. Skills\n",
    "   - List of technical, soft, or domain-specific skills.\n",
    "5. Projects\n",
    "   - Project titles, descriptions, tech stack, roles played, outcomes.\n",
    "6. Certifications / Awards / Achievements (optional section)\n",
    "   - Any notable recognitions, certificates, honors.\n",
    "7. Publications / Research (optional section)\n",
    "   - Any academic publications or relevant research contributions.\n",
    "---\n",
    "🔍 Guidelines for Output Formatting:\n",
    "- Label each section clearly with headers.\n",
    "- Preserve bullet points, dates, and formatting that help maintain semantic meaning.\n",
    "- If a section is missing or not clearly identifiable, note it as \"Not Found\".\n",
    "- Ensure each chunk is semantically meaningful and self-contained for downstream use in retrieval.\n",
    "- Prefer consistent formatting, such as bullet points or structured lists where appropriate.\n",
    "---\n",
    "✅ Output Format Example:\n",
    "### Personal Details:\n",
    "Name: Jane Doe  \n",
    "Email: jane.doe@email.com  \n",
    "Phone: +1-123-456-7890  \n",
    "LinkedIn: linkedin.com/in/janedoe  \n",
    "GitHub: github.com/janedoe\n",
    "### Education:\n",
    "- B.Sc. in Computer Science, MIT (2016–2020)  \n",
    "  Relevant Coursework: Algorithms, Machine Learning  \n",
    "### Work Experience:\n",
    "- Software Engineer at Google (2021–Present)  \n",
    "  • Built scalable microservices in Go and Python  \n",
    "  • Improved system latency by 30%\n",
    "### Skills:\n",
    "Python, Java, Docker, AWS, SQL, Leadership, Agile\n",
    "### Projects:\n",
    "- Resume Parser App  \n",
    "  • Built using Python and spaCy  \n",
    "  • Extracted structured data from raw resume PDFs\n",
    "### Certifications / Awards / Achievements:\n",
    "- AWS Certified Solutions Architect  \n",
    "- Winner, HackMIT 2019\n",
    "### Publications / Research:\n",
    "Not Found\n",
    "---\n",
    "Now parse the following resume content accordingly:\n",
    "{resume_text} \n",
    "\"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "85e572ac-1262-4f1d-beaf-28edb772635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = open('scratch/kr.md', 'r')\n",
    "\n",
    "k1 = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "421a8de8-e411-426e-a464-d7fed751cee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Koushik M A\n",
      "9742836226  \n",
      "koushikma62@gmail.com\n",
      "linkedin.com/in/koushik-ma-6378001b7  \n",
      "## PROFILE\n",
      "Experienced Data Analytics Consultant with 4+ years in data visualization, product development, and some  exposure to data engineering and data science. Skilled at turning data into clear insights and building easy- to-use visual tools to support business goals. Strong problem-solver with a focus on delivering effective,  data-driven solutions.\n",
      "## PROFESSIONAL EXPERIENCE\n",
      "Mathco (TheMathCompany), \n",
      "Product Engineer - II (Data Visualisation Using Python)\n",
      "- • Guided multiple teams through the product development process, focusing on data visualization and  simplifying complex data science methodologies for better understanding.\n",
      "- • Collaborated closely with customers to ensure that the products aligned with their business needs and  were easy to interpret.\n",
      "- • Successfully converted 2 proof-of-concept (POC) projects into full-time engagements for clients within a  short timeframe, driving significant business growth to our organization.\n",
      "Associate\n",
      "• Worked with Fortune 500 clients to demonstrate data science methodology results in our product.\n",
      "- • Migrated data reading from blob storage to Snowflake and optimized the code, significantly improving  load times and enhancing customer experience.\n",
      "- • Created training materials and trained 100+ employees, including managers, on effectively using the  product and developing data visualization screens.\n",
      "Data Analyst\n",
      "• Tested data science functionalities during the early stages of product development.\n",
      "- • Created 100+ demo applications to showcase product capabilities, helping secure client agreements and  convert some into full-time projects for data visualization.\n",
      "## SKILLS\n",
      "## Technologies:\n",
      "Python, SQL, FastAPI, Basic visualisations in  Power BI\n",
      "Libraries/Framework:\n",
      "NumPy, Pandas, Plotly\n",
      "Tools Used:\n",
      "VS Code, Jupyter notebook  \n",
      "PostgreSQL, Snowflake\n",
      "## EDUCATION\n",
      "University Visvesvaraya College of Engineering,  BE in Computer Science &amp; Engineering; 72.07 Aggregate\n",
      "AWARDS\n",
      "Enterprise Value Award\n",
      "Recognized for driving speed and prioritizing innovation by managing full product development without  the need for new UI development.\n",
      "Aug 2016 - Sep 2020\n",
      "Jul 2024 - present\n",
      "Jul 2022 - Jun 2024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_ = ''\n",
    "for i in k1.split('\\n'):\n",
    "    j = i\n",
    "    if j.strip() != '':\n",
    "        text_ += i +'\\n'\n",
    "print(text_)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4dfea906-04db-4e70-8c49-28c9fbec018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = get_resume_chunking_prompt(text_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "b153a935-37a9-492f-9b09-b0bf150049ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an intelligent document parser designed to preprocess resumes for a Retrieval-Augmented Generation (RAG) system.\n",
      "Your task is to intelligently chunk the given raw resume content into well-defined sections for semantic retrieval. Focus on structuring the data meaningfully and consistently so that downstream models can retrieve relevant information efficiently.\n",
      "Specifically, divide the resume into the following labeled sections:\n",
      "1. Personal Details\n",
      "   - Full name, email, phone number, LinkedIn, GitHub, portfolio links, address (if present).\n",
      "2. Education\n",
      "   - Degrees, institutions, years of study, relevant coursework or achievements.\n",
      "3. Work Experience\n",
      "   - Job titles, company names, duration, responsibilities, technologies used, accomplishments.\n",
      "4. Skills\n",
      "   - List of technical, soft, or domain-specific skills.\n",
      "5. Projects\n",
      "   - Project titles, descriptions, tech stack, roles played, outcomes.\n",
      "6. Certifications / Awards / Achievements (optional section)\n",
      "   - Any notable recognitions, certificates, honors.\n",
      "7. Publications / Research (optional section)\n",
      "   - Any academic publications or relevant research contributions.\n",
      "---\n",
      "🔍 Guidelines for Output Formatting:\n",
      "- Label each section clearly with headers.\n",
      "- Preserve bullet points, dates, and formatting that help maintain semantic meaning.\n",
      "- If a section is missing or not clearly identifiable, note it as \"Not Found\".\n",
      "- Ensure each chunk is semantically meaningful and self-contained for downstream use in retrieval.\n",
      "- Prefer consistent formatting, such as bullet points or structured lists where appropriate.\n",
      "---\n",
      "✅ Output Format Example:\n",
      "### Personal Details:\n",
      "Name: Jane Doe  \n",
      "Email: jane.doe@email.com  \n",
      "Phone: +1-123-456-7890  \n",
      "LinkedIn: linkedin.com/in/janedoe  \n",
      "GitHub: github.com/janedoe\n",
      "### Education:\n",
      "- B.Sc. in Computer Science, MIT (2016–2020)  \n",
      "  Relevant Coursework: Algorithms, Machine Learning  \n",
      "### Work Experience:\n",
      "- Software Engineer at Google (2021–Present)  \n",
      "  • Built scalable microservices in Go and Python  \n",
      "  • Improved system latency by 30%\n",
      "### Skills:\n",
      "Python, Java, Docker, AWS, SQL, Leadership, Agile\n",
      "### Projects:\n",
      "- Resume Parser App  \n",
      "  • Built using Python and spaCy  \n",
      "  • Extracted structured data from raw resume PDFs\n",
      "### Certifications / Awards / Achievements:\n",
      "- AWS Certified Solutions Architect  \n",
      "- Winner, HackMIT 2019\n",
      "### Publications / Research:\n",
      "Not Found\n",
      "---\n",
      "Now parse the following resume content accordingly:\n",
      "## Koushik M A\n",
      "9742836226  \n",
      "koushikma62@gmail.com\n",
      "linkedin.com/in/koushik-ma-6378001b7  \n",
      "## PROFILE\n",
      "Experienced Data Analytics Consultant with 4+ years in data visualization, product development, and some  exposure to data engineering and data science. Skilled at turning data into clear insights and building easy- to-use visual tools to support business goals. Strong problem-solver with a focus on delivering effective,  data-driven solutions.\n",
      "## PROFESSIONAL EXPERIENCE\n",
      "Mathco (TheMathCompany), \n",
      "Product Engineer - II (Data Visualisation Using Python)\n",
      "- • Guided multiple teams through the product development process, focusing on data visualization and  simplifying complex data science methodologies for better understanding.\n",
      "- • Collaborated closely with customers to ensure that the products aligned with their business needs and  were easy to interpret.\n",
      "- • Successfully converted 2 proof-of-concept (POC) projects into full-time engagements for clients within a  short timeframe, driving significant business growth to our organization.\n",
      "Associate\n",
      "• Worked with Fortune 500 clients to demonstrate data science methodology results in our product.\n",
      "- • Migrated data reading from blob storage to Snowflake and optimized the code, significantly improving  load times and enhancing customer experience.\n",
      "- • Created training materials and trained 100+ employees, including managers, on effectively using the  product and developing data visualization screens.\n",
      "Data Analyst\n",
      "• Tested data science functionalities during the early stages of product development.\n",
      "- • Created 100+ demo applications to showcase product capabilities, helping secure client agreements and  convert some into full-time projects for data visualization.\n",
      "## SKILLS\n",
      "## Technologies:\n",
      "Python, SQL, FastAPI, Basic visualisations in  Power BI\n",
      "Libraries/Framework:\n",
      "NumPy, Pandas, Plotly\n",
      "Tools Used:\n",
      "VS Code, Jupyter notebook  \n",
      "PostgreSQL, Snowflake\n",
      "## EDUCATION\n",
      "University Visvesvaraya College of Engineering,  BE in Computer Science &amp; Engineering; 72.07 Aggregate\n",
      "AWARDS\n",
      "Enterprise Value Award\n",
      "Recognized for driving speed and prioritizing innovation by managing full product development without  the need for new UI development.\n",
      "Aug 2016 - Sep 2020\n",
      "Jul 2024 - present\n",
      "Jul 2022 - Jun 2024\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b5f24d54-cf16-456e-a00a-6d08d3d84195",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised DeadlineExceeded: 504 Deadline Exceeded.\n"
     ]
    }
   ],
   "source": [
    "res1 = llm_gemini.invoke(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ae5559c8-8536-4354-ab22-07344842177c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Personal Details:\n",
      "Name: Koushik M A\n",
      "Email: koushikma62@gmail.com\n",
      "Phone: 9742836226\n",
      "LinkedIn: linkedin.com/in/koushik-ma-6378001b7\n",
      "\n",
      "### Education:\n",
      "- University Visvesvaraya College of Engineering, BE in Computer Science & Engineering; 72.07 Aggregate (Aug 2016 - Sep 2020)\n",
      "\n",
      "### Work Experience:\n",
      "- Mathco (TheMathCompany), Product Engineer - II (Data Visualisation Using Python) (Jul 2024 - present)\n",
      "  • Guided multiple teams through the product development process, focusing on data visualization and simplifying complex data science methodologies for better understanding.\n",
      "  • Collaborated closely with customers to ensure that the products aligned with their business needs and were easy to interpret.\n",
      "  • Successfully converted 2 proof-of-concept (POC) projects into full-time engagements for clients within a short timeframe, driving significant business growth to our organization.\n",
      "- Mathco (TheMathCompany), Associate (Jul 2022 - Jun 2024)\n",
      "  • Worked with Fortune 500 clients to demonstrate data science methodology results in our product.\n",
      "  • Migrated data reading from blob storage to Snowflake and optimized the code, significantly improving load times and enhancing customer experience.\n",
      "  • Created training materials and trained 100+ employees, including managers, on effectively using the product and developing data visualization screens.\n",
      "- Mathco (TheMathCompany), Data Analyst\n",
      "  • Tested data science functionalities during the early stages of product development.\n",
      "  • Created 100+ demo applications to showcase product capabilities, helping secure client agreements and convert some into full-time projects for data visualization.\n",
      "\n",
      "### Skills:\n",
      "Technologies: Python, SQL, FastAPI, Basic visualisations in Power BI\n",
      "Libraries/Framework: NumPy, Pandas, Plotly\n",
      "Tools Used: VS Code, Jupyter notebook, PostgreSQL, Snowflake\n",
      "\n",
      "### Projects:\n",
      "Not Found\n",
      "\n",
      "### Certifications / Awards / Achievements:\n",
      "- Enterprise Value Award\n",
      "  Recognized for driving speed and prioritizing innovation by managing full product development without the need for new UI development.\n",
      "\n",
      "### Publications / Research:\n",
      "Not Found\n"
     ]
    }
   ],
   "source": [
    "print(res1.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "fb3f2c51-b11c-46b9-8eb1-85c27e2c72ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "certifications_awards_achievements\n",
      "publications_research\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "resume_info_meta = {  'personal_details': 'personal',\n",
    "                 'education': 'education',\n",
    "                 'work_experience:': 'work experience',\n",
    "                 'skills': 'skills',\n",
    "                 'projects': 'projects',\n",
    "                 'certifications_awards_achievements': ['certifications' ,'awards','achievements'],\n",
    "                 'publications_research': ['publications', 'research']}\n",
    "resume_info_actual = {}\n",
    "for i in res1.content.split('###'):\n",
    "    meta_ = i.strip().split('\\n')[0]\n",
    "    find = \"none\"\n",
    "    for info in resume_info_meta:\n",
    "        if isinstance(resume_info_meta[info],List) :\n",
    "            for key_meta in resume_info_meta[info]:\n",
    "                if key_meta in meta_.lower():\n",
    "                    find = info\n",
    "                    print(find)\n",
    "                    break\n",
    "            if find != \"none\":\n",
    "                break\n",
    "        elif isinstance(resume_info_meta[info],str):\n",
    "            key_meta = resume_info_meta[info]\n",
    "            if key_meta in meta_.lower():\n",
    "                find = info\n",
    "        if find != \"none\":\n",
    "            break\n",
    "    if find in resume_info_meta:\n",
    "        resume_info_actual[find] = i.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "a99375ff-8166-486f-b202-5cafb0f71450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personal_details ^^^^^^^^^^\n",
      "Personal Details:\n",
      "Name: Koushik M A\n",
      "Email: koushikma62@gmail.com\n",
      "Phone: 9742836226\n",
      "LinkedIn: linkedin.com/in/koushik-ma-6378001b7\n",
      "----------------------------------------------------------------------------------------------------\n",
      "education ^^^^^^^^^^\n",
      "Education:\n",
      "- University Visvesvaraya College of Engineering, BE in Computer Science & Engineering; 72.07 Aggregate (Aug 2016 - Sep 2020)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "work_experience: ^^^^^^^^^^\n",
      "Work Experience:\n",
      "- Mathco (TheMathCompany), Product Engineer - II (Data Visualisation Using Python) (Jul 2024 - present)\n",
      "  • Guided multiple teams through the product development process, focusing on data visualization and simplifying complex data science methodologies for better understanding.\n",
      "  • Collaborated closely with customers to ensure that the products aligned with their business needs and were easy to interpret.\n",
      "  • Successfully converted 2 proof-of-concept (POC) projects into full-time engagements for clients within a short timeframe, driving significant business growth to our organization.\n",
      "- Mathco (TheMathCompany), Associate (Jul 2022 - Jun 2024)\n",
      "  • Worked with Fortune 500 clients to demonstrate data science methodology results in our product.\n",
      "  • Migrated data reading from blob storage to Snowflake and optimized the code, significantly improving load times and enhancing customer experience.\n",
      "  • Created training materials and trained 100+ employees, including managers, on effectively using the product and developing data visualization screens.\n",
      "- Mathco (TheMathCompany), Data Analyst\n",
      "  • Tested data science functionalities during the early stages of product development.\n",
      "  • Created 100+ demo applications to showcase product capabilities, helping secure client agreements and convert some into full-time projects for data visualization.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "skills ^^^^^^^^^^\n",
      "Skills:\n",
      "Technologies: Python, SQL, FastAPI, Basic visualisations in Power BI\n",
      "Libraries/Framework: NumPy, Pandas, Plotly\n",
      "Tools Used: VS Code, Jupyter notebook, PostgreSQL, Snowflake\n",
      "----------------------------------------------------------------------------------------------------\n",
      "projects ^^^^^^^^^^\n",
      "Projects:\n",
      "Not Found\n",
      "----------------------------------------------------------------------------------------------------\n",
      "certifications_awards_achievements ^^^^^^^^^^\n",
      "Certifications / Awards / Achievements:\n",
      "- Enterprise Value Award\n",
      "  Recognized for driving speed and prioritizing innovation by managing full product development without the need for new UI development.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "publications_research ^^^^^^^^^^\n",
      "Publications / Research:\n",
      "Not Found\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in resume_info_actual:\n",
    "    print(i,'^'*10)\n",
    "    print(resume_info_actual[i])\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "aec89a48-fa0b-4d1a-aecf-f545fa60a97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data/kr.json', 'w') as f:\n",
    "    json.dump(resume_info_actual, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "bea41107-7bd2-4cee-8ddb-c97e7ef62a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'personal_details': 'Personal Details:\\nName: Koushik M A\\nEmail: koushikma62@gmail.com\\nPhone: 9742836226\\nLinkedIn: linkedin.com/in/koushik-ma-6378001b7',\n",
       " 'education': 'Education:\\n- University Visvesvaraya College of Engineering, BE in Computer Science & Engineering; 72.07 Aggregate (Aug 2016 - Sep 2020)',\n",
       " 'work_experience:': 'Work Experience:\\n- Mathco (TheMathCompany), Product Engineer - II (Data Visualisation Using Python) (Jul 2024 - present)\\n  • Guided multiple teams through the product development process, focusing on data visualization and simplifying complex data science methodologies for better understanding.\\n  • Collaborated closely with customers to ensure that the products aligned with their business needs and were easy to interpret.\\n  • Successfully converted 2 proof-of-concept (POC) projects into full-time engagements for clients within a short timeframe, driving significant business growth to our organization.\\n- Mathco (TheMathCompany), Associate (Jul 2022 - Jun 2024)\\n  • Worked with Fortune 500 clients to demonstrate data science methodology results in our product.\\n  • Migrated data reading from blob storage to Snowflake and optimized the code, significantly improving load times and enhancing customer experience.\\n  • Created training materials and trained 100+ employees, including managers, on effectively using the product and developing data visualization screens.\\n- Mathco (TheMathCompany), Data Analyst\\n  • Tested data science functionalities during the early stages of product development.\\n  • Created 100+ demo applications to showcase product capabilities, helping secure client agreements and convert some into full-time projects for data visualization.',\n",
       " 'skills': 'Skills:\\nTechnologies: Python, SQL, FastAPI, Basic visualisations in Power BI\\nLibraries/Framework: NumPy, Pandas, Plotly\\nTools Used: VS Code, Jupyter notebook, PostgreSQL, Snowflake',\n",
       " 'projects': 'Projects:\\nNot Found',\n",
       " 'certifications_awards_achievements': 'Certifications / Awards / Achievements:\\n- Enterprise Value Award\\n  Recognized for driving speed and prioritizing innovation by managing full product development without the need for new UI development.',\n",
       " 'publications_research': 'Publications / Research:\\nNot Found'}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.load(open('data/kr.json'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
